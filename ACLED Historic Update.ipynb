{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACLED Historic Data Updates\n",
    "ACLED Data can be downloaded via their website here, https://www.acleddata.com/data/. This python notebook will walk you through automating this process. It will download and extract the data in XLSX format, process it, and then use it to update a hosted feature layer in ArcGIS Online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import getpass\n",
    "import math\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from arcgis.gis import GIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup your connection to ArcGIS Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input('Username: ')\n",
    "password = getpass.getpass('Password: ')\n",
    "arcgis_url = 'https://www.arcgis.com'\n",
    "\n",
    "# create your `gis` instance \n",
    "gis = GIS(arcgis_url, username, password)\n",
    "\n",
    "print ('succesfully logged in.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and extract the latest historical zip file from ACLED\n",
    "\n",
    "Set the `region` key to one of:\n",
    "- Africa\n",
    "- Middle East\n",
    "- South and South East Asia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_url = 'https://www.acleddata.com/download/{}/'\n",
    "\n",
    "region = 'Africa'\n",
    "\n",
    "if region == 'Middle East':\n",
    "    url_region_id = '2915'\n",
    "elif region == 'Africa':\n",
    "    url_region_id = '2909'\n",
    "elif region == 'South and South East Asia':\n",
    "    url_region_id = '2912'\n",
    "\n",
    "download_url = download_url.format(url_region_id)\n",
    "\n",
    "print ('downloading historic file for {} ..'.format(region))\n",
    "r = requests.get(download_url)\n",
    "\n",
    "cd = r.headers.get('content-disposition')\n",
    "\n",
    "if cd.endswith('.xlsx\";'):\n",
    "    archive_filename = re.findall('filename=(.+)', cd)[0][1:-2]\n",
    "    with open(archive_filename, 'wb') as output:\n",
    "        output.write(r.content)\n",
    "elif cd.endswith('.zip\";'):\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "    print ('extracting zip file ..')\n",
    "    archive_filename = z.namelist()[0]\n",
    "\n",
    "    z.extractall()\n",
    "    \n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pandas to read in the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('reading xlsx into pandas ..')\n",
    "excel_df = pd.read_excel(io=archive_filename, sheet_name=0)\n",
    "\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in two more columns\n",
    "These columns help us identify the source for each record that will make it easier to make future updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('adding new region column to pandas dataframe ..')\n",
    "excel_df.insert(len(excel_df.columns), 'REGION_FROM_FILE', region)\n",
    "excel_df.insert(len(excel_df.columns), 'ISO3', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the ISO3 code column values based on the first 3 characters of the EVENT_ID_CNTY column. _courtesy of [Stack Overflow](https://stackoverflow.com/questions/12604909/pandas-how-to-change-all-the-values-of-a-column/12605055#12605055)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addISO3(row):\n",
    "    val = row['EVENT_ID_CNTY']  \n",
    "    new_iso3 = ''\n",
    "    try:\n",
    "        new_iso3 = row['EVENT_ID_CNTY'][:3]\n",
    "    except:\n",
    "        print ('unable to create ISO3 code from :: {}'.format(row['EVENT_ID_CNTY']))\n",
    "    return new_iso3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df['ISO3'] = excel_df.apply(addISO3, axis=1)\n",
    "print ('done adding ISO3 code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Historic layer ArcGIS Online Item\n",
    "In our situation, the historic layer is the second (index of 1) layer in the Feature service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historic_item_id = 'a6e330c275dd421a9a3dda6e8e546f3d'\n",
    "historic_item = gis.content.get(itemid=historic_item_id)\n",
    "fl = historic_item.layers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete existing region features\n",
    "When using a hosted feature service in ArcGIS Online with a large amount of features, it's best to chunk up any editing jobs into reasonable sized requests. Here we will delete 1,000 features at a time, deleting existing features by object id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fl.query(where='REGION_FROM_FILE = \\'{}\\''.format(region), return_ids_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This handy python function (from [Stack Overflow](https://stackoverflow.com/a/312464)) to split up the data into chunks of 1,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "l = res['objectIds']\n",
    "delete_chunks = [l[i:i+n] for i in range(0, len(l), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_chunks = len(delete_chunks)\n",
    "for i, chunk in enumerate(delete_chunks):\n",
    "    oids = ','.join(map(str, chunk))\n",
    "    try:\n",
    "        delete_response = fl.delete_features(deletes=oids)\n",
    "        print ('deleted chunk {} of {}'.format(i+1,total_chunks))\n",
    "        clear_output(wait=True)\n",
    "    except Exception as e:\n",
    "        print ('error deleting features')\n",
    "\n",
    "print ('done deleting features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable this line for testing with a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel_df = excel_df.head(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into chunks of 1,000 for adding to the feature layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "list_df = [excel_df[i:i+n] for i in range(0,excel_df.shape[0],n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the features\n",
    "Pandas dataframe has a handy `to_json()` method we can use here. From there, we just construct a feature object and stash it into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_chunks = []\n",
    "for df in list_df:\n",
    "    df_json_string = df.to_json(orient='records')\n",
    "    df_json = json.loads(df_json_string)\n",
    "    features = []\n",
    "    for rec in df_json:\n",
    "        feature = {\n",
    "            'attributes': rec,\n",
    "            'geometry': {\n",
    "                'x': rec['LONGITUDE'],\n",
    "                'y': rec['LATITUDE']\n",
    "            }\n",
    "        }\n",
    "        features.append(feature)\n",
    "    \n",
    "    feature_chunks.append(features)\n",
    "    \n",
    "print ('done creating feature chunks.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the edits to the feature layer\n",
    "Here we loop through each chunk of 1,000 features and apply those edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_length = len(feature_chunks)\n",
    "for i, chunk in enumerate(feature_chunks):\n",
    "    try:\n",
    "        fl.edit_features(adds=chunk)\n",
    "        print ('added chunk {} of {}'.format(i+1, chunk_length))\n",
    "        clear_output(wait=True)\n",
    "    except Exception as e:    \n",
    "        print ('error adding chunk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally send an email when it's all done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "mail_server = 'redowa.esri.com'\n",
    "email_address = 'apfister@esri.com'\n",
    "\n",
    "msg = EmailMessage()\n",
    "msg.set_content('hi there. your python script is done adding the features for the {} region'.format(region))\n",
    "msg['Subject'] = 'Done updating ACLED historic layer'\n",
    "msg['from'] = email_address\n",
    "msg['to'] = email_address\n",
    "\n",
    "s = smtplib.SMTP(mail_server)\n",
    "s.send_message(msg)\n",
    "s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
